{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name                      object\n",
       "category                  object\n",
       "main_category             object\n",
       "currency                  object\n",
       "deadline          datetime64[ns]\n",
       "goal                     float64\n",
       "launched          datetime64[ns]\n",
       "pledged                  float64\n",
       "state                     object\n",
       "backers                    int64\n",
       "country                   object\n",
       "date_diff                  int64\n",
       "funding_status            object\n",
       "rtdate            datetime64[ns]\n",
       "name_length              float64\n",
       "fs_binary                  int64\n",
       "rate                     float64\n",
       "goal_usd                 float64\n",
       "pledged_usd              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "\n",
    "# saved the final dataframe to a new csv file\n",
    "# changed some of the data types\n",
    "df = pd.read_csv('C:/Users/rm2019/PythonProjects/Finaldata.csv',index_col=0)\n",
    "df.launched = pd.to_datetime(df.launched)\n",
    "df.deadline = pd.to_datetime(df.deadline)\n",
    "df.rtdate = pd.to_datetime(df.rtdate)\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# create training and testing data sets\n",
    "# originally I normalized the data but it made no difference to R sq'd outcome\n",
    "outcome = pd.DataFrame(df.fs_binary)\n",
    "# data_norm = ((data - data.mean()) / data.std()\n",
    "data = df[['backers','date_diff','goal_usd','name_length']]\n",
    "data_set = data.join(outcome, how='inner')\n",
    "\n",
    "X_train, y_test = train_test_split(data_set,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear regression model takes arrays\n",
    "# converting dataframe to array\n",
    "ax1 = np.array(X_train['backers'])\n",
    "ax2 = np.array(X_train['date_diff'])\n",
    "ax3 = np.array(X_train['goal_usd'])\n",
    "ax4 = np.array(X_train['name_length'])\n",
    "lx1 = np.array(X_train['fs_binary'])\n",
    "ax1 = ax1.reshape(len(X_train['backers']),1)\n",
    "ax2 = ax2.reshape(len(X_train['date_diff']),1)\n",
    "ax3 = ax3.reshape(len(X_train['goal_usd']),1)\n",
    "ax4 = ax4.reshape(len(X_train['name_length']),1)\n",
    "lx1 = lx1.reshape(len(X_train['fs_binary']),1)\n",
    "# horizontally stacking the arrays into new array of arrays\n",
    "a = np.hstack([ax1,ax2,ax3,ax4])\n",
    "lbl = np.hstack([lx1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# my data had a bunch of NaN's causing really problems with the LR formula\n",
    "# Im replacing the NaN with the column means\n",
    "col_mean = np.nanmean(a, axis=0)\n",
    "inds = np.where(np.isnan(a))\n",
    "a[inds] = np.take(col_mean, inds[1])\n",
    "\n",
    "# running the training model call regression model\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(a,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking all the regression coef and assigning them to a variable\n",
    "b = regression_model.coef_\n",
    "b1 = b[0][0]\n",
    "b2 = b[0][1]\n",
    "b3 = b[0][2]\n",
    "b4 = b[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assigning the intercept to a variable\n",
    "a = regression_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turning the testing data into a series of array like I did\n",
    "# with previous training data\n",
    "ay1 = np.array(y_test['backers'])\n",
    "ay2 = np.array(y_test['date_diff'])\n",
    "ay3 = np.array(y_test['goal_usd'])\n",
    "ay4 = np.array(y_test['name_length'])\n",
    "ly1 = np.array(y_test['fs_binary'])\n",
    "ay1 = ay1.reshape(len(y_test['backers']),1)\n",
    "ay2 = ay2.reshape(len(y_test['date_diff']),1)\n",
    "ay3 = ay3.reshape(len(y_test['goal_usd']),1)\n",
    "ay4 = ay4.reshape(len(y_test['name_length']),1)\n",
    "ly1 = ly1.reshape(len(y_test['fs_binary']),1)\n",
    "b = np.hstack([ay1,ay2,ay3,ay4])\n",
    "lbl_y = np.hstack([ly1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of the NaN values like I did previously with the training data\n",
    "col_mean_y = np.nanmean(b, axis=0)\n",
    "inds = np.where(np.isnan(b))\n",
    "b[inds] = np.take(col_mean_y, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03828688976344263"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# models goodness of fit - 4% -absolutely terrible\n",
    "regression_model.score(b,lbl_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the regression formula and feeding it back into the data set\n",
    "data_set['projection'] = round(a + (b1 * data_set.backers) + (b2 * data_set.date_diff) + (b3 * data_set.goal_usd) + (b4 * data_set.name_length),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the actual outcome and the projection are the same put 1 otherwise 0\n",
    "data_set['result'] = np.where(data_set.fs_binary == data_set.projection,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6454229983045208"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# figure out the number of accurate projections\n",
    "data_set.result.sum() / len(data_set.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
